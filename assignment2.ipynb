1. DATA PREPROCESSING
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer

file_path = "updated_pollution_dataset.csv"  # Replace with your dataset path
data = pd.read_csv(file_path)

print("Dataset Overview:")
print(data.head())
print("\nDataset Info:")
print(data.info())

num_imputer = SimpleImputer(strategy="mean")
cat_imputer = SimpleImputer(strategy="most_frequent")

num_cols = data.select_dtypes(include=["float64", "int64"]).columns
cat_cols = data.select_dtypes(include=["object"]).columns

data[num_cols] = num_imputer.fit_transform(data[num_cols])
data[cat_cols] = cat_imputer.fit_transform(data[cat_cols])

label_encoders = {}
for col in cat_cols:
    le = LabelEncoder()
    data[col] = le.fit_transform(data[col])
    label_encoders[col] = le

scaler = StandardScaler()
data[num_cols] = scaler.fit_transform(data[num_cols])

X = data.drop("Air Quality Levels", axis=1)  # Replace with the actual target column name
y = data["Air Quality Levels"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

print("\nData Preprocessing Completed:")
print("Training Set Size:", X_train.shape)
print("Testing Set Size:", X_test.shape)

2. EXPLORATORY DATA ANALYSIS

import matplotlib.pyplot as plt
import seaborn as sns


plt.figure(figsize=(8, 5))
sns.countplot(x=y)
plt.title("Distribution of Air Quality Levels")
plt.xlabel("Air Quality Levels")
plt.ylabel("Count")
plt.show()

plt.figure(figsize=(12, 8))
sns.heatmap(data[num_cols].corr(), annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Matrix of Numerical Features")
plt.show()

plt.figure(figsize=(12, 6))
for i, col in enumerate(num_cols[:4]):  # Adjust the number of features to display
    plt.subplot(2, 2, i + 1)
    sns.boxplot(x=y, y=data[col])
    plt.title(f"{col} vs Air Quality Levels")
plt.tight_layout()
plt.show()

class_counts = y.value_counts()
print("Class Distribution:\n", class_counts)

from sklearn.ensemble import RandomForestClassifier

rf_temp = RandomForestClassifier(random_state=42)
rf_temp.fit(X_train, y_train)

feature_importance = pd.DataFrame({
    "Feature": X.columns,
    "Importance": rf_temp.feature_importances_
}).sort_values(by="Importance", ascending=False)

plt.figure(figsize=(10, 6))
sns.barplot(x="Importance", y="Feature", data=feature_importance)
plt.title("Feature Importance (Random Forest)")
plt.show()

3.MODEL TRAINING AND EVALUATION

from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import GridSearchCV
from xgboost import XGBClassifier

models = {
    "Logistic Regression": LogisticRegression(max_iter=1000, random_state=42),
    "K-Nearest Neighbors": KNeighborsClassifier(),
    "Decision Tree": DecisionTreeClassifier(random_state=42),
    "Random Forest": RandomForestClassifier(random_state=42),
    "Gradient Boosting": GradientBoostingClassifier(random_state=42),
    "Support Vector Machine": SVC(probability=True, random_state=42),
    "XGBoost": XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)
}

model_results = {}
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    model_results[name] = acc
    print(f"\n{name}:")
    print(f"Accuracy: {acc:.4f}")
    print("Classification Report:")
    print(classification_report(y_test, y_pred))
    print("Confusion Matrix:")
    print(confusion_matrix(y_test, y_pred))

print("\nModel Performance Comparison:")
for name, acc in model_results.items():
    print(f"{name}: {acc:.4f}")

plt.figure(figsize=(10, 6))
plt.bar(model_results.keys(), model_results.values(), color='skyblue')
plt.title("Model Accuracy Comparison")
plt.xlabel("Model")
plt.ylabel("Accuracy")
plt.xticks(rotation=45)
plt.show()


